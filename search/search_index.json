{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"OSG Connect Research Facilitation \u00b6 Welcome to the home page of the OSG Connect Research Facilitation Team documentation Mission \u00b6 The mission of OSG Connect Research Facilitation Team is to advance the work of researchers and campuses via participation in OSG, through consultations on service selection and upstart, training and documentation, and channels for ongoing support. For researchers, the RF Team supports all use of the OSG Connect service, avaiable to individual researchers and research groups working on behalf of affiliation with a US academic/govt/non-profit organization. Contact Us \u00b6 Sign Up for a new OSG Connect account (we'll follow up to meet with you). Open a email thread for OSG Connect support. Via Email: support@osgconnect.net Via Web Open an email thread for general support (best for campuses). Via Email: support@opensciencegrid.org Via Web Internal OSG list for the Research Facilitation team: research-facilitation@listserv.fnal.gov More Information \u00b6 Learn more about the Open Science Grid and capabilities for campuses and researchers here . Learn more about OSG-amenable compute tasks and how to execute them in the OSG Connect documentation.","title":"Home"},{"location":"#osg-connect-research-facilitation","text":"Welcome to the home page of the OSG Connect Research Facilitation Team documentation","title":"OSG Connect Research Facilitation"},{"location":"#mission","text":"The mission of OSG Connect Research Facilitation Team is to advance the work of researchers and campuses via participation in OSG, through consultations on service selection and upstart, training and documentation, and channels for ongoing support. For researchers, the RF Team supports all use of the OSG Connect service, avaiable to individual researchers and research groups working on behalf of affiliation with a US academic/govt/non-profit organization.","title":"Mission"},{"location":"#contact-us","text":"Sign Up for a new OSG Connect account (we'll follow up to meet with you). Open a email thread for OSG Connect support. Via Email: support@osgconnect.net Via Web Open an email thread for general support (best for campuses). Via Email: support@opensciencegrid.org Via Web Internal OSG list for the Research Facilitation team: research-facilitation@listserv.fnal.gov","title":"Contact Us"},{"location":"#more-information","text":"Learn more about the Open Science Grid and capabilities for campuses and researchers here . Learn more about OSG-amenable compute tasks and how to execute them in the OSG Connect documentation.","title":"More Information"},{"location":"accounts-and-projects/accounts/","text":"New Accounts \u00b6 Requirements for Users \u00b6 Users need to satisfy the following in order to be approved: Must provide an institutional email address (e.g. user@university.edu, etc.) Must be affiliated with a US institution or research group Process for Creating/Onboarding New OSG Connect Users \u00b6 Determine correct onboarding process Reply to account request to schedule engagement meeting Meet with the applicant Approve account and add to a login node/project Follow-up If the applicant doesn't respond to the request for the meeting, see the instructions for follow-up below. 1. Determine Correct Onboarding Process \u00b6 Check to see if the account request falls under one of these special cases. If so, please follow the Account Creation Flowchart to route correctly. Special Cases UChicago (Xenon1T, South Pole Telescope) Duke CMS ATLAS Jefferson Lab OSG User School Attendees Individuals who attend the OSG User School in at UWMadison do not need an onboarding meeting and their account creation process can be streamlined. 2. Reply to Account Request to Schedule Engagement Meeting \u00b6 Ticket changes Copy and paste the user's information from the \"Pending Members\" page into the ticket as a note. Initial Response Do they have US institutional email? Standard response (also in the User Support's Canned Responses \"New Account Request - schedule initial meeting\") Thank you for your application for an OSG Connect account. In order to understand your computational research goals and ensure that you get the most out of the Open Science Grid, we schedule a brief meeting as part of the account approval process. See my calendar for my availability (XXXXXXXX - note my XX time zone), and let me know what time would work well for you to meet. Our discussion should take between 30 - 45 minutes, and I can provide a teleconference link, unless you have a more preferable option. Additionally, we can streamline the upstart process by associating your account with an OSG Connect 'project'. If you intend to join an existing OSG Connect project associated with your research group, please let me know the name and PI of that project. Otherwise, we just need the below details to create a new project for you, which other members of your research group could join at a later time. PI Email: PI Department or Organization: PI Institution: Project Field of Science: (out of https://www.nsf.gov/about/research_areas.jsp) Looking forward to meeting you soon! XXSIGNATUREXX If no institutional email (Canned Responses: \"New Account Request - non-institutional email\") We received your application to join OSG Connect. A requirement for using OSG Connect is that you be affiliated with a United States academic, non-profit, or government organization. One way that we verify this affiliation is through an institutional/university email address. Can you please re-apply using your institutional email in the E-mail address field? It may require logging out of the osgconnect.net web portal and logging in again with your institutional credentials. On the login page, where it says \u201cUse your existing organizational login,\u201d please select your institution from the drop-down menu and then \u201ccontinue.\u201d Please let me know if your institution is not listed. I will remove your current application so that you will be able to re-apply. If no apparent connection to US institution (Canned Responses: \"New Account Request - non US\") We received your application for an OSG Connect account. One of the requirements to have an account on OSG Connect is that the applicant needs to have an affiliation with a US-based institution or project. Do you have an affiliation with a US research institution (academic, government, non-profit), or US-based collaboration (if so, which collaboration)? Non-Responsive Applications If someone doesn't respond to the request for a meeting, we will send one follow-up email (a week later) and then reject the account (a week later). If someone doesn't respond to the initial request, set the ticket Type to \"on-boarding - 1 week\" and close the ticket. Once it reopens send this email (Canned Responses: \"New Account Request - no response, pinging\") Let me know if you're still interested in scheduling a brief meeting to create an OSG Connect account. See my previous email below for details. If we don't hear back from you, we'll close your account request in a few days. Set the ticket to \"on-boarding - 1 week\" again and close the ticket again. Once it reopens, reject the person's request and send this email (optional, Canned Responses: \"New Account Request - no response, closing\"\"): Since we haven\u2019t heard from you, we\u2019ll remove your OSG Connect account request. If you decide to pursue OSG Connect in the future, just Sign Up for an account, again. 3. Meet with the Applicant \u00b6 The goal of this meeting is to determine if the applicant's science problem is a good fit for high throughput computing + OSG, to tell them about the OSG (and how it may be similar or different from their previous experiences), and talk about concrete next steps for getting started. Sample onboarding discussion outline: Tell me about your research in general How does computing fit in? Short term and long term priorities What does computing look like (dimensions) for short term goals? One program run or many (how many) For one program run - how long? How much memory? Input/output? Can the workflow be split? Software? If the workflow isn\u2019t OSG friendly -> refer to other computing resources At this point describe HTC (vs HPC if they have previous familiarity) and then OSG How OSG \u201caffects\u201d their software, file transfer and job submission 4. Finish Account Setup \u00b6 Request approval from PI To create new projects with a PI different than the requested user, to join existing projects, send an email to the PI to verify their approval. Approve to enter the osg group: Go to the \" Pending Members \" page of the OSG project and click the \"Approve\" button for the user. Create a project: If the user is joining a new project, it will need to be created at this point. This can be completed by following the steps outlined on the Projects documentation page . Add to their appropriate project: Search for the project (pre-existing or newly-created) under the OSG Projects tab and click on the project name. Click on the \"Add Members\" tab Search for the user and add them to the login node. Add to a login node Go to the Login Nodes tab Choose a login node for the user. If someone has joined an existing group, look up one of their group members and try to put them on the same login node. If they are the first of their group, choose login05 . Click the \"Add User\" button for that submit node. Search for the user and add them to the login node. 5. Follow-Up \u00b6 Send follow-up email Send the following email to the new user (Canned Responses: \"New Account Request - welcome email\") Hi NAME OF USER, I've authorized your login account for OSG Connect and added you to the \"GROUPNAME\" project in OSG (which you can use to run jobs on OSG from any submit point). You should have separate emails confirming these actions. Log In The last step you need to log in is submitting a public ssh key -- see this page for detailed instructions. You should be able to log into your designated OSG Connect login node within a few hours after setting up your ssh key. Submitting Jobs For job submission, we highly recommend looking through the latest [HTCondor Job Submission Tutorial] presentation(https://agenda.hep.wisc.edu/event/1325/session/0/contribution/19/material/slides/0.pdf). Our OSG Connect Quickstart has a few HTCondor examples, and the Data Management guide discusses where and how to stage your data on the login node for for running jobs. Before submitting any jobs on OSG Connect, you\u2019ll want to activate your 'default' submission project so that the required \u2018ProjectName\u2019 option is automatically set for future submissions. On the login node, run: $ connect project Let me know how things go as you submit -- you can email us at this address (support@osgconnect.net) or reply to this thread. We're here to help! Cheers, STAFF MEMBER Ticket clean up Paste notes from onboarding meeting into ticket If there are no outstanding issues, change the status of the ticket to \"closed\" and the Type to \"on-boarding X weeks\". When it re-opens, send a check-in email. If there is no response, mark the ticket as \"resolved\".","title":"Accounts"},{"location":"accounts-and-projects/accounts/#new-accounts","text":"","title":"New Accounts"},{"location":"accounts-and-projects/accounts/#requirements-for-users","text":"Users need to satisfy the following in order to be approved: Must provide an institutional email address (e.g. user@university.edu, etc.) Must be affiliated with a US institution or research group","title":"Requirements for Users"},{"location":"accounts-and-projects/accounts/#process-for-creatingonboarding-new-osg-connect-users","text":"Determine correct onboarding process Reply to account request to schedule engagement meeting Meet with the applicant Approve account and add to a login node/project Follow-up If the applicant doesn't respond to the request for the meeting, see the instructions for follow-up below.","title":"Process for Creating/Onboarding New OSG Connect Users"},{"location":"accounts-and-projects/accounts/#1-determine-correct-onboarding-process","text":"Check to see if the account request falls under one of these special cases. If so, please follow the Account Creation Flowchart to route correctly. Special Cases UChicago (Xenon1T, South Pole Telescope) Duke CMS ATLAS Jefferson Lab OSG User School Attendees Individuals who attend the OSG User School in at UWMadison do not need an onboarding meeting and their account creation process can be streamlined.","title":"1. Determine Correct Onboarding Process"},{"location":"accounts-and-projects/accounts/#2-reply-to-account-request-to-schedule-engagement-meeting","text":"Ticket changes Copy and paste the user's information from the \"Pending Members\" page into the ticket as a note. Initial Response Do they have US institutional email? Standard response (also in the User Support's Canned Responses \"New Account Request - schedule initial meeting\") Thank you for your application for an OSG Connect account. In order to understand your computational research goals and ensure that you get the most out of the Open Science Grid, we schedule a brief meeting as part of the account approval process. See my calendar for my availability (XXXXXXXX - note my XX time zone), and let me know what time would work well for you to meet. Our discussion should take between 30 - 45 minutes, and I can provide a teleconference link, unless you have a more preferable option. Additionally, we can streamline the upstart process by associating your account with an OSG Connect 'project'. If you intend to join an existing OSG Connect project associated with your research group, please let me know the name and PI of that project. Otherwise, we just need the below details to create a new project for you, which other members of your research group could join at a later time. PI Email: PI Department or Organization: PI Institution: Project Field of Science: (out of https://www.nsf.gov/about/research_areas.jsp) Looking forward to meeting you soon! XXSIGNATUREXX If no institutional email (Canned Responses: \"New Account Request - non-institutional email\") We received your application to join OSG Connect. A requirement for using OSG Connect is that you be affiliated with a United States academic, non-profit, or government organization. One way that we verify this affiliation is through an institutional/university email address. Can you please re-apply using your institutional email in the E-mail address field? It may require logging out of the osgconnect.net web portal and logging in again with your institutional credentials. On the login page, where it says \u201cUse your existing organizational login,\u201d please select your institution from the drop-down menu and then \u201ccontinue.\u201d Please let me know if your institution is not listed. I will remove your current application so that you will be able to re-apply. If no apparent connection to US institution (Canned Responses: \"New Account Request - non US\") We received your application for an OSG Connect account. One of the requirements to have an account on OSG Connect is that the applicant needs to have an affiliation with a US-based institution or project. Do you have an affiliation with a US research institution (academic, government, non-profit), or US-based collaboration (if so, which collaboration)? Non-Responsive Applications If someone doesn't respond to the request for a meeting, we will send one follow-up email (a week later) and then reject the account (a week later). If someone doesn't respond to the initial request, set the ticket Type to \"on-boarding - 1 week\" and close the ticket. Once it reopens send this email (Canned Responses: \"New Account Request - no response, pinging\") Let me know if you're still interested in scheduling a brief meeting to create an OSG Connect account. See my previous email below for details. If we don't hear back from you, we'll close your account request in a few days. Set the ticket to \"on-boarding - 1 week\" again and close the ticket again. Once it reopens, reject the person's request and send this email (optional, Canned Responses: \"New Account Request - no response, closing\"\"): Since we haven\u2019t heard from you, we\u2019ll remove your OSG Connect account request. If you decide to pursue OSG Connect in the future, just Sign Up for an account, again.","title":"2. Reply to Account Request to Schedule Engagement Meeting"},{"location":"accounts-and-projects/accounts/#3-meet-with-the-applicant","text":"The goal of this meeting is to determine if the applicant's science problem is a good fit for high throughput computing + OSG, to tell them about the OSG (and how it may be similar or different from their previous experiences), and talk about concrete next steps for getting started. Sample onboarding discussion outline: Tell me about your research in general How does computing fit in? Short term and long term priorities What does computing look like (dimensions) for short term goals? One program run or many (how many) For one program run - how long? How much memory? Input/output? Can the workflow be split? Software? If the workflow isn\u2019t OSG friendly -> refer to other computing resources At this point describe HTC (vs HPC if they have previous familiarity) and then OSG How OSG \u201caffects\u201d their software, file transfer and job submission","title":"3. Meet with the Applicant"},{"location":"accounts-and-projects/accounts/#4-finish-account-setup","text":"Request approval from PI To create new projects with a PI different than the requested user, to join existing projects, send an email to the PI to verify their approval. Approve to enter the osg group: Go to the \" Pending Members \" page of the OSG project and click the \"Approve\" button for the user. Create a project: If the user is joining a new project, it will need to be created at this point. This can be completed by following the steps outlined on the Projects documentation page . Add to their appropriate project: Search for the project (pre-existing or newly-created) under the OSG Projects tab and click on the project name. Click on the \"Add Members\" tab Search for the user and add them to the login node. Add to a login node Go to the Login Nodes tab Choose a login node for the user. If someone has joined an existing group, look up one of their group members and try to put them on the same login node. If they are the first of their group, choose login05 . Click the \"Add User\" button for that submit node. Search for the user and add them to the login node.","title":"4. Finish Account Setup"},{"location":"accounts-and-projects/accounts/#5-follow-up","text":"Send follow-up email Send the following email to the new user (Canned Responses: \"New Account Request - welcome email\") Hi NAME OF USER, I've authorized your login account for OSG Connect and added you to the \"GROUPNAME\" project in OSG (which you can use to run jobs on OSG from any submit point). You should have separate emails confirming these actions. Log In The last step you need to log in is submitting a public ssh key -- see this page for detailed instructions. You should be able to log into your designated OSG Connect login node within a few hours after setting up your ssh key. Submitting Jobs For job submission, we highly recommend looking through the latest [HTCondor Job Submission Tutorial] presentation(https://agenda.hep.wisc.edu/event/1325/session/0/contribution/19/material/slides/0.pdf). Our OSG Connect Quickstart has a few HTCondor examples, and the Data Management guide discusses where and how to stage your data on the login node for for running jobs. Before submitting any jobs on OSG Connect, you\u2019ll want to activate your 'default' submission project so that the required \u2018ProjectName\u2019 option is automatically set for future submissions. On the login node, run: $ connect project Let me know how things go as you submit -- you can email us at this address (support@osgconnect.net) or reply to this thread. We're here to help! Cheers, STAFF MEMBER Ticket clean up Paste notes from onboarding meeting into ticket If there are no outstanding issues, change the status of the ticket to \"closed\" and the Type to \"on-boarding X weeks\". When it re-opens, send a check-in email. If there is no response, mark the ticket as \"resolved\".","title":"5. Follow-Up"},{"location":"accounts-and-projects/general/","text":"OSG User Support Internal Documentation \u00b6 Creating Accounts in OSG Connect. \u00b6 The account creation workflow for OSG Connect follows a fairly straightforward workflow: Users enter through one of the Connect websites, e.g. www.osgconnect.net The default should be that they sign in via CILogon, using their institutional identity. If they don't have an institution that's part of CILogon, they should use Globus. Completing the login steps will generate a profile that is \"pending\" in the osg group (which represents all accounts on OSG Connect) An e-mail gets sent to \"Manager\"s and \"Admin\"s of the top-level connect project and a ticket gets created in FreshDesk At this point, a member of the OSG support team steps in and follows the steps listed in the guide on creating new accounts After the account has been approved, a login node assigned, and an ssh key uploaded, the person's account should be generated on the appropriate login node within 30 minutes. Updating Accounts in OSG Connect \u00b6 The only updates that need to be made to a user account are: Change SSH key Changing the user SSH key needs to be performed by the user by going to https://www.osgconnect.net/profile, clicking on \"Edit Profile\" and then adding or changing their ssh key. Change project membership To add a user to a project, either the user can request being added to the project, or have a \"Manager\"/\"Admin\" invite the user to the project. If the user is a member of the top-level project, e.g. osg , a \"Manager\"/\"Admin\" can \"invite\" the user and the user is added to the group automatically. If the user is not a member of the top-level project, the user can request membership in an project or a a \"Manager\"/\"Admin\" can \"invite\" the user. If the user is invited, the user will receive and email and have to accept the invitation. Delete user To delete a user, the \"Manager\"/\"Admin\" can simply remove the user from the project. In all these cases, the synchronization step will propagate the changes from Globus through the json file to puppet and ultimately the servers. Known Issues \u00b6 Username during Sign up procedure \u00b6 One issue that appears in about 1/3 of user sign ups is that the user uses a non-Globus ID to request membership in the respective top-level project. This is caused by the fact that the user link their institutional credentials to their Globus ID or never create a Globus ID. The former is much more frequent than the latter. If the user has a Globus ID, one can invite them to the group with that. The user will receive an email that they need to accept. This step also allows one to check whether the user has a Globus ID. OSG Stash Globus Endpoint \u00b6 If the user does not have the Globus ID as their primary ID, e.g. their institutional ID or their GMail, the setup of the Globus endpoint for OSG Stash will not work. This has to do with using the Globus MyProxy server as the source for authentication. Without having the Globus ID as the primary, this will not work.","title":"General"},{"location":"accounts-and-projects/general/#osg-user-support-internal-documentation","text":"","title":"OSG User Support Internal Documentation"},{"location":"accounts-and-projects/general/#creating-accounts-in-osg-connect","text":"The account creation workflow for OSG Connect follows a fairly straightforward workflow: Users enter through one of the Connect websites, e.g. www.osgconnect.net The default should be that they sign in via CILogon, using their institutional identity. If they don't have an institution that's part of CILogon, they should use Globus. Completing the login steps will generate a profile that is \"pending\" in the osg group (which represents all accounts on OSG Connect) An e-mail gets sent to \"Manager\"s and \"Admin\"s of the top-level connect project and a ticket gets created in FreshDesk At this point, a member of the OSG support team steps in and follows the steps listed in the guide on creating new accounts After the account has been approved, a login node assigned, and an ssh key uploaded, the person's account should be generated on the appropriate login node within 30 minutes.","title":"Creating Accounts in OSG Connect."},{"location":"accounts-and-projects/general/#updating-accounts-in-osg-connect","text":"The only updates that need to be made to a user account are: Change SSH key Changing the user SSH key needs to be performed by the user by going to https://www.osgconnect.net/profile, clicking on \"Edit Profile\" and then adding or changing their ssh key. Change project membership To add a user to a project, either the user can request being added to the project, or have a \"Manager\"/\"Admin\" invite the user to the project. If the user is a member of the top-level project, e.g. osg , a \"Manager\"/\"Admin\" can \"invite\" the user and the user is added to the group automatically. If the user is not a member of the top-level project, the user can request membership in an project or a a \"Manager\"/\"Admin\" can \"invite\" the user. If the user is invited, the user will receive and email and have to accept the invitation. Delete user To delete a user, the \"Manager\"/\"Admin\" can simply remove the user from the project. In all these cases, the synchronization step will propagate the changes from Globus through the json file to puppet and ultimately the servers.","title":"Updating Accounts in OSG Connect"},{"location":"accounts-and-projects/general/#known-issues","text":"","title":"Known Issues"},{"location":"accounts-and-projects/general/#username-during-sign-up-procedure","text":"One issue that appears in about 1/3 of user sign ups is that the user uses a non-Globus ID to request membership in the respective top-level project. This is caused by the fact that the user link their institutional credentials to their Globus ID or never create a Globus ID. The former is much more frequent than the latter. If the user has a Globus ID, one can invite them to the group with that. The user will receive an email that they need to accept. This step also allows one to check whether the user has a Globus ID.","title":"Username during Sign up procedure"},{"location":"accounts-and-projects/general/#osg-stash-globus-endpoint","text":"If the user does not have the Globus ID as their primary ID, e.g. their institutional ID or their GMail, the setup of the Globus endpoint for OSG Stash will not work. This has to do with using the Globus MyProxy server as the source for authentication. Without having the Globus ID as the primary, this will not work.","title":"OSG Stash Globus Endpoint"},{"location":"accounts-and-projects/gosync3/","text":"GOSync3 \u00b6 GOSync3 is the replacement for the original GOSync. It is based on the Globus SDK , the Globus SDK-based Globus Nexus Client , and puppet/hiera to create and manage UNIX users and groups. The main tasks of these classes and scripts are to interact with the GlobusID and Globus Groups database through their RESTful API and manage the JSON file that puppet/hiera requires for creating and managing user accounts. The original GOSync is based on the Globus Nexus Python library . The Globus Nexus Python library has been officially deprecated. An improved version of the original GOSync, i.e. GOSync2, was under development. It was still based on the Globus Nexus Python library. The development was abandoned as Globus has moved to a OAuth2-based authentication model and access to a user's GlobusID. Important notes READ BEFORE USING: This is a BETA. It does not have all the necessary features to act as a full replacement yet. This version uses Globus Nexus client based on the Globus SDK created by Stephen Rosen. This is not an official product of the Globus team. It is maintained though. Assumptions \u00b6 Following assumptions are made in the code: All users are part of the connect Globus Group The connect user is an admin or manager in all relevant groups Work flow \u00b6 The GOSync3 work flow is meant to operate without human intervention, i.e. as a cron job, besides the normal user approval process. At the moment, there is no connection between account applications and GOSync3. Hence, there is no way of knowing which user is new, updated his/her profile, or changed their group membership. This should change in the future, see the last section for details. In the current work flow, GOSync3 retrieves all groups in which the connect user is an Administrator or Manager . The connect user acts like the root user in a UNIX operating system. In addition to the group name and the UUID assigned by Globus Groups, the number of active members is being fetched by querying the group's summary from Globus. For creating and updating users the work flow is more complicated. First, GOSync3 retrieves all users and their profile associated with the root group, i.e. connect . It is necessary to fetch the user profile because it contains the user's SSH key. To determine the the user's group membership, the the group to users mapping is generated by looping through all groups getting their group members. FRom this mapping a user to groups mapping is generated. With the necessary information in hand, it the user information in the JSON object is created or updated. Prerequisites \u00b6 GOSync3 requires at least Python 2.7 and Python packages: globus - sdk [ jwt ]>= 1.0 , < 2.0 globus - nexus - client >= 0.2.5 globus-sdk[jwt]>=1.0,<2.0 is the Globus SDK including the JSON Web Token (JWT) library. JWT is necessary to interact with Globus Auth and be able to do token introspection. globus-nexus-client>=0.2.5 is an implementation of the Nexus client using the Globus SDK. It is not an official Globus product, but supported by one of the authors (Stephen Rosen) of the Globus SDK. In addition to the Python packages, one will need a Globus Confidential application, see here for details, that: Includes the user-granted permissions (\"scopes\"): openid profile email urn:globus:auth:scope:auth.globus.org:view_identity_set urn:globus:auth:scope:auth.globus.org:view_identities urn:globus:auth:scope:transfer.api.globus.org:all urn:globus:auth:scope:auth.globus.org:view_ssh_public_keys Is allowed to use the Group scopes. This requires filing a ticket with Globus to get the app ID added to the system Has the correct redirection URLs (this depends on the website you are running) Requires the GlobusID as an identity provider Has a secret associated with the application For more details, please see the Globus SDK documentation . Configuration \u00b6 The configuration is a JSON file for ease of parsing it as a dictionary. The minimal configuration needed is: { \"users\": { \"passwd_file\": <passwd_file_to_be_used> \"default_group\": <default_group for users> }, \"groups\": { \"group_file\": <group_file_to_be_used> }, \"globus\": { \"groups\": { \"root_group\": <root_group>, \"root_group_uuid\": <root_group_globus_uuid> }, \"root_user\": { // root user should only have admin or manager roles in the groups \"roles\": [ \"admin\", \"manager\" ], \"username\": <root_user>, \"secret\": <root_user_passwd>, \"auth_refresh_token\": <root_user_globus_auth_token_for_app>, \"nexus_refresh_token\": <root_user_globus_nexus_token_for_app> }, \"user\": { // regular user may have any role in a group \"roles\": [ \"member\", \"admin\", \"manager\" ] }, \"app\": { \"scopes\": [ \"openid\", \"profile\", \"email\", \"urn:globus:auth:scope:auth.globus.org:view_identities\", \"urn:globus:auth:scope:transfer.api.globus.org:all\", \"urn:globus:auth:scope:auth.globus.org:view_identity_set\", \"urn:globus:auth:scope:nexus.api.globus.org:groups\" ], \"client_id\": <globus_app_id_as_string>, \"client_secret\": <globus_app_secret_as_string> } }, \"connect_db\": { \"db_file\": <json_file_to_be_used_as_connect_db> } } This JSON object will be parsed into a Python dictionary and will be passed to the various classes. Execute code \u00b6 Syncing User and Groups - gosync_globus_auth.py \u00b6 Executing gosync_globus_auth.py will sync the users and groups from Globus. If you want to run with you own config: ./gosync_globus_auth.py --config /path/to/config . If you want to increase the verbosity, default the program will not print out anything to screen, simply add the -v flag. To increase the verbosity, just add more v s, i.e. -vvvv . Adding Group - add_connect_group.py \u00b6 To add a group to Globus Groups requires, a file formatted as provided by the OSG Connect Website, details below. With the groups project file, a group is added through executing ./add_connect_group.py --projectfile /path/to/file --parent <parent_group> . The --parent <parent_group> is optional, but necessary to maintain the group tree structure and determine the correct group name in Globus. To pass your own configuration you will need to the --config /path/to/new/config option. There is also a verbosity flag, i.e. -v , -vv , and -vvv . Globus Interface - globus_db.py \u00b6 The class globus_db is meant as an interface to the Globus ID and Globus Groups services. Please note that being able to PUT and PUSH information into Globus Groups is possible through the Nexus interface. Currently, only the PUT for Globus Groups is supported. The class requires a configuration dictionary and an connect_db object. The configuration dictionary is explained above. The connect_db is needed to retrieve the the refresh tokens for users and allow of to check for changes in group membership, i.e. if users were added or removed from a group. The class is split into four sections: client methods, group methods, group membership methods, and user methods. Client Methods and some explanation about various Globus tokens \u00b6 The client methods are for getting the different types of clients needed to interact with GlobusID through Globus Auth and Globus Groups through Globus Nexus. There are two main clients used: Globus Auth client and Globus Nexus client. The Globus Auth client is for interacting with the user's GlobusID, i.e get the user profile in GlobusID. The Globus Nexus client is for interacting with a user's Globus Groups and their Globus Groups's profile. The clients can be authenticated using Globus Auth tokens or Globus Online Auth legacy tokens. Tokens can be thought of as randomly generated passwords that encode the user's identity and the application's permission level. Globus Online Auth legacy tokens will be referred to as legacy tokens from here on out. Legacy tokens should be avoided at all cost. They may not work down the road and are bad practice. Globus Auth tokens are OAuth2 tokens. OAuth2 gives the user and the authorization server the explicit power to reject or limit (either in time or scope) an application's access, to the user's information. It also moves large parts of the authentication process from the resource provider to an authentication provider, which allows for better separation between resources and authentication. For more details please visit An introduction to OAuth2 . The Globus Auth tokens are split into three different types: Auth, Transfer, and Nexus. One will receive one, two, or all three, when a user authenticates against the app depending on an app's scopes, i.e. requested permissions. With the app created in the prerequisites one will receive all three tokens. Auth tokens are meant for retrieving a user's information from Globus ID, i.e. linked identities, SSH keys, etc. Transfer tokens are for initiating Globus transfers on behalf of the user. Nexus tokens are for authorizing against the Globus Groups service to allow viewing a user's group membership. The Nexus tokens do not allow to view a user's Globus groups profile through a call to the user's Globus Nexus profile, i.e. the group-specific custom fields and the user identity, directly. This due to the Nexus group scope not having the permissions to view the user's GlobusID. This can be circumvented by through accessing the profile through the groups interface instead. I know... Please note that Nexus tokens are special. They are not officially available, one has to request access to the \"group\" scopes from Globus. Globus Auth tokens expire after some time, usually within 10 minutes, i.e. you as the application only have a limited amount of time to retrieve the desired information out of Globus. To be able to repeatedly authenticate with Globus Auth, one can request \"refresh tokens\". These tokens are valid until the user revokes an app's permission. These are required for GOSync3. The individual methods are self-explanatory: get_tokens : Returns a user's tokens from the connect_db or retrieves the tokens from the configuration file for the root user. get_legacy_client : Returns a user's Nexus client that has been authenticated using legacy Globus Online Auth token, i.e. the user's username/password. get_globus_client : Returns the user's Globus Auth and Globus Nexus client authenticated using the user's refresh tokens. Group Methods \u00b6 Retrieving Group Infomation - GET Methods \u00b6 There are two ways to access all groups associated with connect . The first is to the retrieve the group tree for the root group, named connect . The second is to retrieve all groups associated with the root user, also named connect . In GOSyn3, we are using the second method. There is a method to retrieve the group tree, but it is unused at the moment. The get_group and get_groups method simply filter the all_groups list for the desired group(s). get_all_groups is the method that uses the root user's credentials to determine groups in which the root user, connect , is an admin or manager . The distinction between between being admin , manager , or member is important here. It filters the groups that are returned by Globus Nexus. The connect user will always be an admin or manager in a subgroup, while a user might be a admin , manager , or member . The root user is a member of some groups that are not associated with the Connect instances. In addition there is a check_new_members methods at is currently used. It allows to filter the group list to those groups that have recently added members. Adding Group Information - POST Methods \u00b6 GOSync3 has the ability to add groups to Globus Groups. This is done through the add_group and parse_project_file methods. Adding a group is done through the add_groups method. It calls the globus-nexus-client 's create_group method to create the group with name and description provided through the project description text file, details on this below. Optionally, one can pass a parent group to the method. It is strongly recommended to provide a parent group, without a group the group will be assumed to be a top-level group below the root connect group. The project description text file should follow the format of the form on the New Project section on the OSG Connect website . This will provide a text file of the following format: Your Name: Your Email Address: Project Name: Short Project Name: Field of Science: Evolutionary Field of Science (if Other): PI Name: PI Email: PI Organization: PI Department: Join Date: Sponsor: OSG Sponsor Contact: Project Contact: Project Contact Email: Telephone Number: Project Description: From this the only required field is the \"Short Project Name\". The value will be used as the group name in Globus Groups. parse_project_file parses the project file, determines the expected name of the group, and converts the plain text to HTML-formatted text. The project name is determined from the \"Short Project Name\" in the project file and the parent group. The format of the Globus Groups name is <parent_group>.<short_project_name . To make the text HTML-formatted, the only action is to converted newline characters ( \\n ) to <br> . Group Membership Methods \u00b6 The work flow for retrieving a user's group membership depends on the authentication method used. In a purely Globus Auth-based workflow, one would retrieve a user's group membership by using their tokens and calling list_groups method from the Nexus client. This is done in the function get_user_groups_auth . At the moment, we only have tokens for the connect user. To work around this, GOSync3 tries to generate a mapping of group to users first and then inverts that mapping, see function get_user_groups_no_tokens . It retrieves the list of all groups associated with the connect user and then determines the group members for every group. Using _invert_dict_list_values , the group-to-users mapping is then inverted to the user-to-groups mapping. get_group_members simply returns the users for a given group. This has to be done using the group's Globus UUID. A mapping of Globus group name to Globus group UUID is provided by the connect_db . User Methods \u00b6 The user methods allow the user to retrieve more information about user, i.e. query Globus for the user's \"user information\" and manipulate the Globus output in a more easily digestible patterns. get_user_info is a specialization of get_user_groups_profile . It allows to fetch the a user's profile, i.e. username, SSH key, group-specific information, full name, e-mail, through Globus Groups. get_user_info is specialization in the sense that it uses the root group user profile rather than specific group's profile as needed by get_user_groups_profile . get_all_users retrieves all the users in the root group and then queries Globus Groups for the user's profile. _invert_dict_list_values allows you to invert the group to users mapping to a user to groups mapping. Puppet/Hiera Interface - connect_db.py \u00b6 In this case, the JSON file used by puppet/hiera is used as a user database. This is suboptimal. It will allow us to quickly deploy GOSync3. The information source for the puppet/hiera JSON file can be replaced by a real DB later on. Some of the information, i.e. UNIX ids, stored in the JSON file will be needed to populate a replacement database. The puppet/hiera interface, i.e connect_db , is a thin layer of the JSON object that puppet/hiera uses to provision user accounts. It reads a previous version of the JSON object, and produces a users and groups dictionary and a uids and gids list. These four objects contain all the necessary information to be able add new groups and users to the JSON object passed to puppet/hiera. The users and groups dictionaries are made up of sub-dictionaries. Holding the information for each user and group, respectively. The users dictionary is a mapping of username to user information, such that: { \"auth_refresh_token\": # user's Globus Auth refresh token \"comment\": # user's name \"email\": # user's emails \"gid\": # default group for passwd file \"manage_group\": # puppet/hiera config parameter \"nexus_refresh_token\": # user's Globus Nexus refresh token \"shell\": # default user shell \"ssh_keys\": # SSH key dictionary, explained below \"uid\": # user's UNIX id \"groups\": # list of user's groups, \"connect_project\": # Initial connect project, typically osg.ConnectTrain \"condor_schedd\": # The condor schedd to pick on the login host } The groups dictionary follows a similar pattern. Mapping a group name to: { \"gid\": # group UNIX ID \"num_members\": # Number if active user according to Globus \"globus_uuid\": # Groups Globus UUID } Some of the methods in this class are self-explanatory: add_group : Add a new group to the groups dictionary add_user : Add a new user to the users dictionary get_user : Retrieve the user information by username get_group : Retrieve the group by group name new_unix_id : This will generate a new UNIX id by incrementing the maximum ID or setting it to 100000 for both groups and users get_member_count : Retrieve the group's active member count get_auth_token : Retrieve user's Globus Auth refresh token get_nexus_token : Retrieve user's Globus Nexus refresh token get_globus_tokens : Retrieves user's Globus Auth and Nexus refresh tokens remove_unicode : Remove unicode characters from a user's name. This can cause problems when generating a passwd file or trying to serialize a JSON file. commit_old_version : In the spirit of old GOSync, we commit the JSON file to Gitlab, so puppet/hiera can grab it from there write_db : Write the JSON object out. If email_file is supplied in the config, it will also create a directory with json files that maps the group users to their email addresses. Similarly, if mailchimp_file is supplied, it will also create a directory with json files that maps the group users to their information needed for mailchimp. set_user_nologin : Set a user's shell to nologin, used in case they are no longer \"active\" in a Globus group get_emails : Get email for everyone or optionally for a given group get_email : Get email for a specific user get_mailchimp_info : Gather information about users for mailchimp. Mapping users to their, first name, last name, and email address. The get_default_project method is tries to guess a user's first OSG project for account reasons. If the user is a member of more than more than one sub-project we need to filter out any of the default ones. First, \"osg.ConnectTrain\" is removed. If there are still more than one projects, we filter out any project associated with a user school and any OSG project, if the user is a member of the other connect instances, i.e. SPT, ATLAS, CMS, and Duke. The decompose_sshkey method is necessary because of the format that puppet/hiera wants the SSH key in. A typical SSH key is formatted as follows: <encryption_type> <public_key> <idenitifier> where the <encryption_type> is the type of SSH key, i.e. ssh-rsa, <public_key> is the actual key portion of an SSH key, and <idenitifier> is an optional identifier that is usually <username>@<network_hostname> of the machine the key pair was generated on. Puppet/hiera wants the key in this JSON object: { \"<identifier>\": { \"type\": <encryption_type> # Encryption type, i.e. ssh-rsa, ssh-dsa \"key\": <public_key> # Key part } } This requires to split the key according to the spaces it in. Unfortunately, not all keys have the identifier. In those cases it is replaced with the user's email address. This will not affect operations. There is a question though about overriding SSH keys. Future Plans \u00b6 Work flow Improvements \u00b6 There are three slow processes in the current work flow: Getting the group summary Getting the user summary Getting the user group memberships The first processes are slow because we have to query the Globus Groups database separately each piece of the group information: group profile, number of members, and group members, respectively. In addition, queries on the Globus side slow down as the group tree grows in size and as we add more groups the more queries we have to perform. Getting the user summary is a similarly expensive process because we have to query Globus for every user twice, once to get their general information, and another to get their SSH key. One of the main steps to improve the efficiency requires to change the website to use OAuth2. This would allow us to operate on a per-user basis rather than on a per-group basis. In an idealized work flow, a user would sign up on the website. This sign up process would trigger the ability to retrieve the users identity (including their SSH key)and their Globus OAuth tokens, see below for more details on Globus OAuth tokens. With the identity and Globus token in hand, we can then query Globus for just the new user's group memberships. The first query would happen be default at sign up, while the group membership query would come after they are approved. The second query may have to be repeated several time. This is not wasted effort though, since we are waiting for human intervention. Similarly, we could trigger a Globus query of a given user's profile once they login. This would make updating the user information on our end dependent on user actions rather than us having to repeatedly query Globus for their information. Given that we most likely will never have tokens for all users, we will need operate in a hybrid mode, where the new user's are handled solely through the tokens, while older users will have still have to be kept up to date through the above described work flow. PUT and PUSH Methods for Globus Interface \u00b6 To create groups in Globus Groups, we will need to implement PUSH methods. The NexusClient already has these, but they are untested. I will need to test them before I can sanction them. I also want to standardize all information that is stored in Globus Groups for all the groups. Currently there are several different formats. Moving connect DB to a real DB \u00b6 The data volume is not that large and the JSON file is sufficient to store all the information. Down the road, we might want split from Globus and at this point we need to retrieve all the data from Globus. Storing this data would need a database. Multiple Connect Globus Apps \u00b6 Branded websites in Globus are mapped one-to-one to a specific Globus App. To have different branded website for the various connect instances, we would need multiple Globus Apps. Tokens are app-specific, so for users that are members of multiple connect instances, for example CI Connect and OSG Connect, we will need to keep track of different refresh tokens and apps that they are associated with.","title":"GoSync3"},{"location":"accounts-and-projects/gosync3/#gosync3","text":"GOSync3 is the replacement for the original GOSync. It is based on the Globus SDK , the Globus SDK-based Globus Nexus Client , and puppet/hiera to create and manage UNIX users and groups. The main tasks of these classes and scripts are to interact with the GlobusID and Globus Groups database through their RESTful API and manage the JSON file that puppet/hiera requires for creating and managing user accounts. The original GOSync is based on the Globus Nexus Python library . The Globus Nexus Python library has been officially deprecated. An improved version of the original GOSync, i.e. GOSync2, was under development. It was still based on the Globus Nexus Python library. The development was abandoned as Globus has moved to a OAuth2-based authentication model and access to a user's GlobusID. Important notes READ BEFORE USING: This is a BETA. It does not have all the necessary features to act as a full replacement yet. This version uses Globus Nexus client based on the Globus SDK created by Stephen Rosen. This is not an official product of the Globus team. It is maintained though.","title":"GOSync3"},{"location":"accounts-and-projects/gosync3/#assumptions","text":"Following assumptions are made in the code: All users are part of the connect Globus Group The connect user is an admin or manager in all relevant groups","title":"Assumptions"},{"location":"accounts-and-projects/gosync3/#work-flow","text":"The GOSync3 work flow is meant to operate without human intervention, i.e. as a cron job, besides the normal user approval process. At the moment, there is no connection between account applications and GOSync3. Hence, there is no way of knowing which user is new, updated his/her profile, or changed their group membership. This should change in the future, see the last section for details. In the current work flow, GOSync3 retrieves all groups in which the connect user is an Administrator or Manager . The connect user acts like the root user in a UNIX operating system. In addition to the group name and the UUID assigned by Globus Groups, the number of active members is being fetched by querying the group's summary from Globus. For creating and updating users the work flow is more complicated. First, GOSync3 retrieves all users and their profile associated with the root group, i.e. connect . It is necessary to fetch the user profile because it contains the user's SSH key. To determine the the user's group membership, the the group to users mapping is generated by looping through all groups getting their group members. FRom this mapping a user to groups mapping is generated. With the necessary information in hand, it the user information in the JSON object is created or updated.","title":"Work flow"},{"location":"accounts-and-projects/gosync3/#prerequisites","text":"GOSync3 requires at least Python 2.7 and Python packages: globus - sdk [ jwt ]>= 1.0 , < 2.0 globus - nexus - client >= 0.2.5 globus-sdk[jwt]>=1.0,<2.0 is the Globus SDK including the JSON Web Token (JWT) library. JWT is necessary to interact with Globus Auth and be able to do token introspection. globus-nexus-client>=0.2.5 is an implementation of the Nexus client using the Globus SDK. It is not an official Globus product, but supported by one of the authors (Stephen Rosen) of the Globus SDK. In addition to the Python packages, one will need a Globus Confidential application, see here for details, that: Includes the user-granted permissions (\"scopes\"): openid profile email urn:globus:auth:scope:auth.globus.org:view_identity_set urn:globus:auth:scope:auth.globus.org:view_identities urn:globus:auth:scope:transfer.api.globus.org:all urn:globus:auth:scope:auth.globus.org:view_ssh_public_keys Is allowed to use the Group scopes. This requires filing a ticket with Globus to get the app ID added to the system Has the correct redirection URLs (this depends on the website you are running) Requires the GlobusID as an identity provider Has a secret associated with the application For more details, please see the Globus SDK documentation .","title":"Prerequisites"},{"location":"accounts-and-projects/gosync3/#configuration","text":"The configuration is a JSON file for ease of parsing it as a dictionary. The minimal configuration needed is: { \"users\": { \"passwd_file\": <passwd_file_to_be_used> \"default_group\": <default_group for users> }, \"groups\": { \"group_file\": <group_file_to_be_used> }, \"globus\": { \"groups\": { \"root_group\": <root_group>, \"root_group_uuid\": <root_group_globus_uuid> }, \"root_user\": { // root user should only have admin or manager roles in the groups \"roles\": [ \"admin\", \"manager\" ], \"username\": <root_user>, \"secret\": <root_user_passwd>, \"auth_refresh_token\": <root_user_globus_auth_token_for_app>, \"nexus_refresh_token\": <root_user_globus_nexus_token_for_app> }, \"user\": { // regular user may have any role in a group \"roles\": [ \"member\", \"admin\", \"manager\" ] }, \"app\": { \"scopes\": [ \"openid\", \"profile\", \"email\", \"urn:globus:auth:scope:auth.globus.org:view_identities\", \"urn:globus:auth:scope:transfer.api.globus.org:all\", \"urn:globus:auth:scope:auth.globus.org:view_identity_set\", \"urn:globus:auth:scope:nexus.api.globus.org:groups\" ], \"client_id\": <globus_app_id_as_string>, \"client_secret\": <globus_app_secret_as_string> } }, \"connect_db\": { \"db_file\": <json_file_to_be_used_as_connect_db> } } This JSON object will be parsed into a Python dictionary and will be passed to the various classes.","title":"Configuration"},{"location":"accounts-and-projects/gosync3/#execute-code","text":"","title":"Execute code"},{"location":"accounts-and-projects/gosync3/#syncing-user-and-groups-gosync_globus_authpy","text":"Executing gosync_globus_auth.py will sync the users and groups from Globus. If you want to run with you own config: ./gosync_globus_auth.py --config /path/to/config . If you want to increase the verbosity, default the program will not print out anything to screen, simply add the -v flag. To increase the verbosity, just add more v s, i.e. -vvvv .","title":"Syncing User and Groups - gosync_globus_auth.py"},{"location":"accounts-and-projects/gosync3/#adding-group-add_connect_grouppy","text":"To add a group to Globus Groups requires, a file formatted as provided by the OSG Connect Website, details below. With the groups project file, a group is added through executing ./add_connect_group.py --projectfile /path/to/file --parent <parent_group> . The --parent <parent_group> is optional, but necessary to maintain the group tree structure and determine the correct group name in Globus. To pass your own configuration you will need to the --config /path/to/new/config option. There is also a verbosity flag, i.e. -v , -vv , and -vvv .","title":"Adding Group - add_connect_group.py"},{"location":"accounts-and-projects/gosync3/#globus-interface-globus_dbpy","text":"The class globus_db is meant as an interface to the Globus ID and Globus Groups services. Please note that being able to PUT and PUSH information into Globus Groups is possible through the Nexus interface. Currently, only the PUT for Globus Groups is supported. The class requires a configuration dictionary and an connect_db object. The configuration dictionary is explained above. The connect_db is needed to retrieve the the refresh tokens for users and allow of to check for changes in group membership, i.e. if users were added or removed from a group. The class is split into four sections: client methods, group methods, group membership methods, and user methods.","title":"Globus Interface - globus_db.py"},{"location":"accounts-and-projects/gosync3/#client-methods-and-some-explanation-about-various-globus-tokens","text":"The client methods are for getting the different types of clients needed to interact with GlobusID through Globus Auth and Globus Groups through Globus Nexus. There are two main clients used: Globus Auth client and Globus Nexus client. The Globus Auth client is for interacting with the user's GlobusID, i.e get the user profile in GlobusID. The Globus Nexus client is for interacting with a user's Globus Groups and their Globus Groups's profile. The clients can be authenticated using Globus Auth tokens or Globus Online Auth legacy tokens. Tokens can be thought of as randomly generated passwords that encode the user's identity and the application's permission level. Globus Online Auth legacy tokens will be referred to as legacy tokens from here on out. Legacy tokens should be avoided at all cost. They may not work down the road and are bad practice. Globus Auth tokens are OAuth2 tokens. OAuth2 gives the user and the authorization server the explicit power to reject or limit (either in time or scope) an application's access, to the user's information. It also moves large parts of the authentication process from the resource provider to an authentication provider, which allows for better separation between resources and authentication. For more details please visit An introduction to OAuth2 . The Globus Auth tokens are split into three different types: Auth, Transfer, and Nexus. One will receive one, two, or all three, when a user authenticates against the app depending on an app's scopes, i.e. requested permissions. With the app created in the prerequisites one will receive all three tokens. Auth tokens are meant for retrieving a user's information from Globus ID, i.e. linked identities, SSH keys, etc. Transfer tokens are for initiating Globus transfers on behalf of the user. Nexus tokens are for authorizing against the Globus Groups service to allow viewing a user's group membership. The Nexus tokens do not allow to view a user's Globus groups profile through a call to the user's Globus Nexus profile, i.e. the group-specific custom fields and the user identity, directly. This due to the Nexus group scope not having the permissions to view the user's GlobusID. This can be circumvented by through accessing the profile through the groups interface instead. I know... Please note that Nexus tokens are special. They are not officially available, one has to request access to the \"group\" scopes from Globus. Globus Auth tokens expire after some time, usually within 10 minutes, i.e. you as the application only have a limited amount of time to retrieve the desired information out of Globus. To be able to repeatedly authenticate with Globus Auth, one can request \"refresh tokens\". These tokens are valid until the user revokes an app's permission. These are required for GOSync3. The individual methods are self-explanatory: get_tokens : Returns a user's tokens from the connect_db or retrieves the tokens from the configuration file for the root user. get_legacy_client : Returns a user's Nexus client that has been authenticated using legacy Globus Online Auth token, i.e. the user's username/password. get_globus_client : Returns the user's Globus Auth and Globus Nexus client authenticated using the user's refresh tokens.","title":"Client Methods and some explanation about various Globus tokens"},{"location":"accounts-and-projects/gosync3/#group-methods","text":"","title":"Group Methods"},{"location":"accounts-and-projects/gosync3/#retrieving-group-infomation-get-methods","text":"There are two ways to access all groups associated with connect . The first is to the retrieve the group tree for the root group, named connect . The second is to retrieve all groups associated with the root user, also named connect . In GOSyn3, we are using the second method. There is a method to retrieve the group tree, but it is unused at the moment. The get_group and get_groups method simply filter the all_groups list for the desired group(s). get_all_groups is the method that uses the root user's credentials to determine groups in which the root user, connect , is an admin or manager . The distinction between between being admin , manager , or member is important here. It filters the groups that are returned by Globus Nexus. The connect user will always be an admin or manager in a subgroup, while a user might be a admin , manager , or member . The root user is a member of some groups that are not associated with the Connect instances. In addition there is a check_new_members methods at is currently used. It allows to filter the group list to those groups that have recently added members.","title":"Retrieving Group Infomation - GET Methods"},{"location":"accounts-and-projects/gosync3/#adding-group-information-post-methods","text":"GOSync3 has the ability to add groups to Globus Groups. This is done through the add_group and parse_project_file methods. Adding a group is done through the add_groups method. It calls the globus-nexus-client 's create_group method to create the group with name and description provided through the project description text file, details on this below. Optionally, one can pass a parent group to the method. It is strongly recommended to provide a parent group, without a group the group will be assumed to be a top-level group below the root connect group. The project description text file should follow the format of the form on the New Project section on the OSG Connect website . This will provide a text file of the following format: Your Name: Your Email Address: Project Name: Short Project Name: Field of Science: Evolutionary Field of Science (if Other): PI Name: PI Email: PI Organization: PI Department: Join Date: Sponsor: OSG Sponsor Contact: Project Contact: Project Contact Email: Telephone Number: Project Description: From this the only required field is the \"Short Project Name\". The value will be used as the group name in Globus Groups. parse_project_file parses the project file, determines the expected name of the group, and converts the plain text to HTML-formatted text. The project name is determined from the \"Short Project Name\" in the project file and the parent group. The format of the Globus Groups name is <parent_group>.<short_project_name . To make the text HTML-formatted, the only action is to converted newline characters ( \\n ) to <br> .","title":"Adding Group Information - POST Methods"},{"location":"accounts-and-projects/gosync3/#group-membership-methods","text":"The work flow for retrieving a user's group membership depends on the authentication method used. In a purely Globus Auth-based workflow, one would retrieve a user's group membership by using their tokens and calling list_groups method from the Nexus client. This is done in the function get_user_groups_auth . At the moment, we only have tokens for the connect user. To work around this, GOSync3 tries to generate a mapping of group to users first and then inverts that mapping, see function get_user_groups_no_tokens . It retrieves the list of all groups associated with the connect user and then determines the group members for every group. Using _invert_dict_list_values , the group-to-users mapping is then inverted to the user-to-groups mapping. get_group_members simply returns the users for a given group. This has to be done using the group's Globus UUID. A mapping of Globus group name to Globus group UUID is provided by the connect_db .","title":"Group Membership Methods"},{"location":"accounts-and-projects/gosync3/#user-methods","text":"The user methods allow the user to retrieve more information about user, i.e. query Globus for the user's \"user information\" and manipulate the Globus output in a more easily digestible patterns. get_user_info is a specialization of get_user_groups_profile . It allows to fetch the a user's profile, i.e. username, SSH key, group-specific information, full name, e-mail, through Globus Groups. get_user_info is specialization in the sense that it uses the root group user profile rather than specific group's profile as needed by get_user_groups_profile . get_all_users retrieves all the users in the root group and then queries Globus Groups for the user's profile. _invert_dict_list_values allows you to invert the group to users mapping to a user to groups mapping.","title":"User Methods"},{"location":"accounts-and-projects/gosync3/#puppethiera-interface-connect_dbpy","text":"In this case, the JSON file used by puppet/hiera is used as a user database. This is suboptimal. It will allow us to quickly deploy GOSync3. The information source for the puppet/hiera JSON file can be replaced by a real DB later on. Some of the information, i.e. UNIX ids, stored in the JSON file will be needed to populate a replacement database. The puppet/hiera interface, i.e connect_db , is a thin layer of the JSON object that puppet/hiera uses to provision user accounts. It reads a previous version of the JSON object, and produces a users and groups dictionary and a uids and gids list. These four objects contain all the necessary information to be able add new groups and users to the JSON object passed to puppet/hiera. The users and groups dictionaries are made up of sub-dictionaries. Holding the information for each user and group, respectively. The users dictionary is a mapping of username to user information, such that: { \"auth_refresh_token\": # user's Globus Auth refresh token \"comment\": # user's name \"email\": # user's emails \"gid\": # default group for passwd file \"manage_group\": # puppet/hiera config parameter \"nexus_refresh_token\": # user's Globus Nexus refresh token \"shell\": # default user shell \"ssh_keys\": # SSH key dictionary, explained below \"uid\": # user's UNIX id \"groups\": # list of user's groups, \"connect_project\": # Initial connect project, typically osg.ConnectTrain \"condor_schedd\": # The condor schedd to pick on the login host } The groups dictionary follows a similar pattern. Mapping a group name to: { \"gid\": # group UNIX ID \"num_members\": # Number if active user according to Globus \"globus_uuid\": # Groups Globus UUID } Some of the methods in this class are self-explanatory: add_group : Add a new group to the groups dictionary add_user : Add a new user to the users dictionary get_user : Retrieve the user information by username get_group : Retrieve the group by group name new_unix_id : This will generate a new UNIX id by incrementing the maximum ID or setting it to 100000 for both groups and users get_member_count : Retrieve the group's active member count get_auth_token : Retrieve user's Globus Auth refresh token get_nexus_token : Retrieve user's Globus Nexus refresh token get_globus_tokens : Retrieves user's Globus Auth and Nexus refresh tokens remove_unicode : Remove unicode characters from a user's name. This can cause problems when generating a passwd file or trying to serialize a JSON file. commit_old_version : In the spirit of old GOSync, we commit the JSON file to Gitlab, so puppet/hiera can grab it from there write_db : Write the JSON object out. If email_file is supplied in the config, it will also create a directory with json files that maps the group users to their email addresses. Similarly, if mailchimp_file is supplied, it will also create a directory with json files that maps the group users to their information needed for mailchimp. set_user_nologin : Set a user's shell to nologin, used in case they are no longer \"active\" in a Globus group get_emails : Get email for everyone or optionally for a given group get_email : Get email for a specific user get_mailchimp_info : Gather information about users for mailchimp. Mapping users to their, first name, last name, and email address. The get_default_project method is tries to guess a user's first OSG project for account reasons. If the user is a member of more than more than one sub-project we need to filter out any of the default ones. First, \"osg.ConnectTrain\" is removed. If there are still more than one projects, we filter out any project associated with a user school and any OSG project, if the user is a member of the other connect instances, i.e. SPT, ATLAS, CMS, and Duke. The decompose_sshkey method is necessary because of the format that puppet/hiera wants the SSH key in. A typical SSH key is formatted as follows: <encryption_type> <public_key> <idenitifier> where the <encryption_type> is the type of SSH key, i.e. ssh-rsa, <public_key> is the actual key portion of an SSH key, and <idenitifier> is an optional identifier that is usually <username>@<network_hostname> of the machine the key pair was generated on. Puppet/hiera wants the key in this JSON object: { \"<identifier>\": { \"type\": <encryption_type> # Encryption type, i.e. ssh-rsa, ssh-dsa \"key\": <public_key> # Key part } } This requires to split the key according to the spaces it in. Unfortunately, not all keys have the identifier. In those cases it is replaced with the user's email address. This will not affect operations. There is a question though about overriding SSH keys.","title":"Puppet/Hiera Interface - connect_db.py"},{"location":"accounts-and-projects/gosync3/#future-plans","text":"","title":"Future Plans"},{"location":"accounts-and-projects/gosync3/#work-flow-improvements","text":"There are three slow processes in the current work flow: Getting the group summary Getting the user summary Getting the user group memberships The first processes are slow because we have to query the Globus Groups database separately each piece of the group information: group profile, number of members, and group members, respectively. In addition, queries on the Globus side slow down as the group tree grows in size and as we add more groups the more queries we have to perform. Getting the user summary is a similarly expensive process because we have to query Globus for every user twice, once to get their general information, and another to get their SSH key. One of the main steps to improve the efficiency requires to change the website to use OAuth2. This would allow us to operate on a per-user basis rather than on a per-group basis. In an idealized work flow, a user would sign up on the website. This sign up process would trigger the ability to retrieve the users identity (including their SSH key)and their Globus OAuth tokens, see below for more details on Globus OAuth tokens. With the identity and Globus token in hand, we can then query Globus for just the new user's group memberships. The first query would happen be default at sign up, while the group membership query would come after they are approved. The second query may have to be repeated several time. This is not wasted effort though, since we are waiting for human intervention. Similarly, we could trigger a Globus query of a given user's profile once they login. This would make updating the user information on our end dependent on user actions rather than us having to repeatedly query Globus for their information. Given that we most likely will never have tokens for all users, we will need operate in a hybrid mode, where the new user's are handled solely through the tokens, while older users will have still have to be kept up to date through the above described work flow.","title":"Work flow Improvements"},{"location":"accounts-and-projects/gosync3/#put-and-push-methods-for-globus-interface","text":"To create groups in Globus Groups, we will need to implement PUSH methods. The NexusClient already has these, but they are untested. I will need to test them before I can sanction them. I also want to standardize all information that is stored in Globus Groups for all the groups. Currently there are several different formats.","title":"PUT and PUSH Methods for Globus Interface"},{"location":"accounts-and-projects/gosync3/#moving-connect-db-to-a-real-db","text":"The data volume is not that large and the JSON file is sufficient to store all the information. Down the road, we might want split from Globus and at this point we need to retrieve all the data from Globus. Storing this data would need a database.","title":"Moving connect DB to a real DB"},{"location":"accounts-and-projects/gosync3/#multiple-connect-globus-apps","text":"Branded websites in Globus are mapped one-to-one to a specific Globus App. To have different branded website for the various connect instances, we would need multiple Globus Apps. Tokens are app-specific, so for users that are members of multiple connect instances, for example CI Connect and OSG Connect, we will need to keep track of different refresh tokens and apps that they are associated with.","title":"Multiple Connect Globus Apps"},{"location":"accounts-and-projects/projects/","text":"Projects \u00b6 Creating a project in OSG Connect requires three steps. Create the project on the portal \u00b6 To create a new project using the OSGConnect.net portal, click \"Create Project\" button in the Admin panel on osgconnect.net. Complete the provided form. You will need the following information: Requester Name: Requester Email Address: Project Name (short project name): Display Name (descriptive project name): Field of Science: PI Name: PI Email: PI Organization: Project Description: Please only use NSF-aligned Field of Sciences for the \"Field of Science\". Click \"Submit\" to add the new project. Add the user to the project \u00b6 After the project file has been created, add the required users to the project. If you are doing this step immediately after creating the project, skip to step < > below Go to https://www.osgconnect.net and login Click on the \"Projects\" tab on the Admin panel Find the new project, using \"Search\" if desired, and open the project by clicking on the long name Click on the \"Add Members\" and find the target user, using \"Search\" if desired/necessary Add the user to the project by clicking the \"Add Member\" button next to their entry Add the project to topology \u00b6 The project will also need to be added to the OSG topology at https://github.com/opensciencegrid/topology/tree/master/projects Clone the topology repository and cd into it. git clone https://github.com/opensciencegrid/topology cd topology Run the \"next project id\" script in the bin/ directory: bin/next_project_id That will give you the ID number for the new project. To add a new project file, you will need to ensure you are working within your own (forked) version of the repository. If you have not already done so, fork the topology repository by visiting https://github.com/opensciencegrid/topology, clicking \"Fork\". Detailed information for setting up and maintaining your fork can be found in the GitHub documentation page . Within your forked repository, go into the projects folder and create a project file. The project file should be named the same as the short (UNIX) project name. It usually makes sense to copy from another project file that was also created for an OSG Connect project so the sponsor information is already correct. Fill in the appropriate information, including the ID number you got from the previous step. In order to maintain consistancy in organization naming structure, please use the bin/list_organizations function to ensure the name you are using matches this list. Commit the new project file and submit a PR.","title":"Projects"},{"location":"accounts-and-projects/projects/#projects","text":"Creating a project in OSG Connect requires three steps.","title":"Projects"},{"location":"accounts-and-projects/projects/#create-the-project-on-the-portal","text":"To create a new project using the OSGConnect.net portal, click \"Create Project\" button in the Admin panel on osgconnect.net. Complete the provided form. You will need the following information: Requester Name: Requester Email Address: Project Name (short project name): Display Name (descriptive project name): Field of Science: PI Name: PI Email: PI Organization: Project Description: Please only use NSF-aligned Field of Sciences for the \"Field of Science\". Click \"Submit\" to add the new project.","title":"Create the project on the portal"},{"location":"accounts-and-projects/projects/#add-the-user-to-the-project","text":"After the project file has been created, add the required users to the project. If you are doing this step immediately after creating the project, skip to step < > below Go to https://www.osgconnect.net and login Click on the \"Projects\" tab on the Admin panel Find the new project, using \"Search\" if desired, and open the project by clicking on the long name Click on the \"Add Members\" and find the target user, using \"Search\" if desired/necessary Add the user to the project by clicking the \"Add Member\" button next to their entry","title":"Add the user to the project"},{"location":"accounts-and-projects/projects/#add-the-project-to-topology","text":"The project will also need to be added to the OSG topology at https://github.com/opensciencegrid/topology/tree/master/projects Clone the topology repository and cd into it. git clone https://github.com/opensciencegrid/topology cd topology Run the \"next project id\" script in the bin/ directory: bin/next_project_id That will give you the ID number for the new project. To add a new project file, you will need to ensure you are working within your own (forked) version of the repository. If you have not already done so, fork the topology repository by visiting https://github.com/opensciencegrid/topology, clicking \"Fork\". Detailed information for setting up and maintaining your fork can be found in the GitHub documentation page . Within your forked repository, go into the projects folder and create a project file. The project file should be named the same as the short (UNIX) project name. It usually makes sense to copy from another project file that was also created for an OSG Connect project so the sponsor information is already correct. Fill in the appropriate information, including the ID number you got from the previous step. In order to maintain consistancy in organization naming structure, please use the bin/list_organizations function to ensure the name you are using matches this list. Commit the new project file and submit a PR.","title":"Add the project to topology"},{"location":"documentation/freshdesk/","text":"Managing Documentation in Freshdesk \u00b6 Brief overview: source for the documentation is in markdown files in the documentation repository. \"Empty\" articles are created and organized in categories in Freshdesk. Each article has a numeric identifier. The freshpush.ini file maps the markdown documents in the repository to the appropriate numeric identifier so that the content gets pushed into that article in Freshdesk. For more details, see this page . Relevant links: Documentation repository: https://github.com/OSGConnect/connectbook Freshdesk solutions: https://support.opensciencegrid.org/a/solutions/ Rendered Docs: https://support.opensciencegrid.org/support/home Style guide: https://opensciencegrid.org/technology/documentation/style-guide/ Adding a Document \u00b6 Original documentation here Reorganizing Content \u00b6 Manage folders and article hierarchy in Freshdesk. You have to update organization in markdown files in connectbook repository manually; however, we like to do this to make it easier to find the appropriate markdown file to make changes. Editing a Document \u00b6 Original Documentation here Archiving or Removing a Document \u00b6 Clone the documentation repository if you haven't already. git clone --recursive https://github.com/OSGConnect/connectbook.git Move the file to the archive folder. git mv document.md archive git commit -a -m \"archiving document\" Remove that document's entry from update/freshpush.ini In Freshdesk, delete the corresponding article.","title":"Freshdesk"},{"location":"documentation/freshdesk/#managing-documentation-in-freshdesk","text":"Brief overview: source for the documentation is in markdown files in the documentation repository. \"Empty\" articles are created and organized in categories in Freshdesk. Each article has a numeric identifier. The freshpush.ini file maps the markdown documents in the repository to the appropriate numeric identifier so that the content gets pushed into that article in Freshdesk. For more details, see this page . Relevant links: Documentation repository: https://github.com/OSGConnect/connectbook Freshdesk solutions: https://support.opensciencegrid.org/a/solutions/ Rendered Docs: https://support.opensciencegrid.org/support/home Style guide: https://opensciencegrid.org/technology/documentation/style-guide/","title":"Managing Documentation in Freshdesk"},{"location":"documentation/freshdesk/#adding-a-document","text":"Original documentation here","title":"Adding a Document"},{"location":"documentation/freshdesk/#reorganizing-content","text":"Manage folders and article hierarchy in Freshdesk. You have to update organization in markdown files in connectbook repository manually; however, we like to do this to make it easier to find the appropriate markdown file to make changes.","title":"Reorganizing Content"},{"location":"documentation/freshdesk/#editing-a-document","text":"Original Documentation here","title":"Editing a Document"},{"location":"documentation/freshdesk/#archiving-or-removing-a-document","text":"Clone the documentation repository if you haven't already. git clone --recursive https://github.com/OSGConnect/connectbook.git Move the file to the archive folder. git mv document.md archive git commit -a -m \"archiving document\" Remove that document's entry from update/freshpush.ini In Freshdesk, delete the corresponding article.","title":"Archiving or Removing a Document"},{"location":"documentation/github/","text":"Setting up OSG repositories on GitHub \u00b6 Setting up a topology repository fork \u00b6 The topology repository does not allow for direct commits so all changes will need to be submitted via pull requests from personal forked repositories. This can create challenges keeping your copy up to date with changes made to the official repository. Create a personal fork of the topology repository To do this, visit the repository page at https://github.com/opensciencegrid/topology/ and click the \"Fork\" button found in the top right corner. Clone the repository onto your local machine using the following command where is your GitHub account name or the organization name that your repository was associated with. git clone https://github.com/ /topology.git cd topology Establish the correct upstream repository In order to pull down changes made to the main repository into yours, an upstream remote will need to be set. From within your forked repository folder, do the following: List current configured remote repository for your fork: $ git remote -v origin https://github.com/ /topology.git (fetch) origin https://github.com/ /topology.git (push) Add a new remote upstream repository that will be synced with the fork: git remote add upstream https://github.com/opensciencegrid/topology/ Verify the new upstream repository: $ git remote -v origin https://github.com/ /topology.git (fetch) origin https://github.com/ /topology.git (push) upstream https://github.com/opensciencegrid/topology/ (fetch) upstream https://github.com/opensciencegrid/topology/ (push) Making Changes and Creating Pull Requests \u00b6 Pull down upstream changes Before creating any changes, it is best to pull down upstream changes to avoid merge conflicts. To do this, use the command: git pull upstream master Make changes in your local fork Add and/or change any necessary files and commit them to your local repository. Create pull request Submit a new pull request to the official topology repository from your fork.","title":"Setting up OSG repositories on GitHub"},{"location":"documentation/github/#setting-up-osg-repositories-on-github","text":"","title":"Setting up OSG repositories on GitHub"},{"location":"documentation/github/#setting-up-a-topology-repository-fork","text":"The topology repository does not allow for direct commits so all changes will need to be submitted via pull requests from personal forked repositories. This can create challenges keeping your copy up to date with changes made to the official repository. Create a personal fork of the topology repository To do this, visit the repository page at https://github.com/opensciencegrid/topology/ and click the \"Fork\" button found in the top right corner. Clone the repository onto your local machine using the following command where is your GitHub account name or the organization name that your repository was associated with. git clone https://github.com/ /topology.git cd topology Establish the correct upstream repository In order to pull down changes made to the main repository into yours, an upstream remote will need to be set. From within your forked repository folder, do the following: List current configured remote repository for your fork: $ git remote -v origin https://github.com/ /topology.git (fetch) origin https://github.com/ /topology.git (push) Add a new remote upstream repository that will be synced with the fork: git remote add upstream https://github.com/opensciencegrid/topology/ Verify the new upstream repository: $ git remote -v origin https://github.com/ /topology.git (fetch) origin https://github.com/ /topology.git (push) upstream https://github.com/opensciencegrid/topology/ (fetch) upstream https://github.com/opensciencegrid/topology/ (push)","title":"Setting up a topology repository fork"},{"location":"documentation/github/#making-changes-and-creating-pull-requests","text":"Pull down upstream changes Before creating any changes, it is best to pull down upstream changes to avoid merge conflicts. To do this, use the command: git pull upstream master Make changes in your local fork Add and/or change any necessary files and commit them to your local repository. Create pull request Submit a new pull request to the official topology repository from your fork.","title":"Making Changes and Creating Pull Requests"},{"location":"general/cvmfs/","text":"CVMFS \u00b6 UChicago hosts the CVMFS origin server ( osg-cvmfs.grid.uchicago.edu ) for several experiments and the OSG module system. This server is a CentOS7 VM with singularity that can be used to build EL6 versions of software. The repositories are associated with a respective user, e.g. spt.opensciencegrid.org has an spt user, that are typically accessible to the relevant members of the experiments. The VM is fairly large with 8 cores and 16 GB RAM. The /cvmfs directory is a separate disk that can be resized if need be. Modules \u00b6 The modules are hosted out of the connect.opensciencegrid.org subrepo. They are setup using spack . A good place to start understanding spack is the spack tutuorial available here . There is a fork of spack in the OSG Connect GitHub which contains a few necessary changes and additional packages. The main change required for OSG is that CentOS instances are considered the same as RHEL or SL. This is an artifact from using the python platform package. Path Structure \u00b6 The structure for the software is as follows: /cvmfs/connect.opensciencegrid.org modules - Main directory spack - Spack instances packages - Where individual packages are installed * modulefiles - Where lmod files are located Configuration \u00b6 There are some important spack config files that may need adjusting over time, esp. when trying to reconfigure the module structure or adding new features: SPACK_ROOT=/cvmfs/connect.opensciencegrid.org/modules/spack $HOME/.spack/linux/compilers.yaml This defines the compilers that can be used by spack. We currently list two compilers by default here: GCC 4.8.5 installed using spack and GCC 6.4.0 also installed using spack. We had to install GCC 4.8.5 (system compiler for EL7) because certain programs, e.g. R, require libgfortran to be present to run. This is not guaranteed on OSG since some nodes do not have any development tools installed. GCC 6.4.0 is needed for support for C++14. $SPACK_ROOT/etc/spack/config.yaml Defines global configuration parameters for spack. In our case this is just where the packages will installed ( install_tree ) and where the module files will be located ( module_roots/lmod ). For other options see (here)[https://spack.readthedocs.io/en/latest/config_yaml.html#config-yaml] $SPACK_ROOT/etc/spack/packages.yaml Defines the global or package specific settings for build variants. This means that it allows one to turn on or off certain package-specific configuration parameters. In our case, we want to disable the need for packages to compile with MPI support and reduce the number of versions of certain libraries, e.g. always compile libxml2 with python support. $SPACK_ROOT/etc/spack/modules.yaml Defines the organization and general settings for creating module files. For example, in our cause we have suffixes to differentiate versions that depend on Python 2.7 and 3.7 and only the lmod modules are enabled. Adding a Module \u00b6 Adding a new module is fairly straight forward. On the CVMFS origin host, log in as the connect user. Now start a CVMFS transaction: cvmfs_server transaction connect.opensciencegrid.org Please note that only a single transaction can be open at a time, so if you don't finish the transaction (for example building ROOT takes hours) no one else can add new modules while a transaction is active. Once the transaction has been started, go to the spack bin directory, $SPACK_ROOT/bin/ : cd /cvmfs/connect.opensciencegrid.org/modules/spack/bin If the desired piece of software and version is available in the (spack package list)[https://spack.readthedocs.io/en/latest/package_list.html], simply run spack install <package>@<version>%gcc@<gcc_version> To check what <gcc_version> s are available see $HOME/.spack/linux/compilers.yaml Adding a new version of a piece of software requires editing the respective package file using spack edit <package> Adding a new package is fairly straightforward as well. Simply run spack create <url_to_package_tarball> and edit the resulting file as needed, e.g. add dependencies, add configure/cmake options, etc. For examples check out various other packages in $SPACK_ROOT/var/spack/repos/builtin/packages/ . Experiments \u00b6 SPT \u00b6 See Midscale-Engagements XENON \u00b6 See Midscale-Engagements VERITAS \u00b6 See Midscale-Engagements nEXO \u00b6 The nEXO repository is handled by OSG personnel. The organization is the same as the SPT repos. The repo is very much in flux because of the development of the nEXO MonteCarlo software. Dependency List \u00b6 Shortened list Boost 1.67.0 cmake 3.11.1 geant4 10.04.p01 python 2.7.14 ROOT 6.12.06 with builtin_fftw3, using our gsl 1.16, minuit on, caster off, roofit on, rfio off, xrootd off, gfal and ruby disabled vgm 4.4 http://ivana.home.cern.ch","title":"CVMFS"},{"location":"general/cvmfs/#cvmfs","text":"UChicago hosts the CVMFS origin server ( osg-cvmfs.grid.uchicago.edu ) for several experiments and the OSG module system. This server is a CentOS7 VM with singularity that can be used to build EL6 versions of software. The repositories are associated with a respective user, e.g. spt.opensciencegrid.org has an spt user, that are typically accessible to the relevant members of the experiments. The VM is fairly large with 8 cores and 16 GB RAM. The /cvmfs directory is a separate disk that can be resized if need be.","title":"CVMFS"},{"location":"general/cvmfs/#modules","text":"The modules are hosted out of the connect.opensciencegrid.org subrepo. They are setup using spack . A good place to start understanding spack is the spack tutuorial available here . There is a fork of spack in the OSG Connect GitHub which contains a few necessary changes and additional packages. The main change required for OSG is that CentOS instances are considered the same as RHEL or SL. This is an artifact from using the python platform package.","title":"Modules"},{"location":"general/cvmfs/#path-structure","text":"The structure for the software is as follows: /cvmfs/connect.opensciencegrid.org modules - Main directory spack - Spack instances packages - Where individual packages are installed * modulefiles - Where lmod files are located","title":"Path Structure"},{"location":"general/cvmfs/#configuration","text":"There are some important spack config files that may need adjusting over time, esp. when trying to reconfigure the module structure or adding new features: SPACK_ROOT=/cvmfs/connect.opensciencegrid.org/modules/spack $HOME/.spack/linux/compilers.yaml This defines the compilers that can be used by spack. We currently list two compilers by default here: GCC 4.8.5 installed using spack and GCC 6.4.0 also installed using spack. We had to install GCC 4.8.5 (system compiler for EL7) because certain programs, e.g. R, require libgfortran to be present to run. This is not guaranteed on OSG since some nodes do not have any development tools installed. GCC 6.4.0 is needed for support for C++14. $SPACK_ROOT/etc/spack/config.yaml Defines global configuration parameters for spack. In our case this is just where the packages will installed ( install_tree ) and where the module files will be located ( module_roots/lmod ). For other options see (here)[https://spack.readthedocs.io/en/latest/config_yaml.html#config-yaml] $SPACK_ROOT/etc/spack/packages.yaml Defines the global or package specific settings for build variants. This means that it allows one to turn on or off certain package-specific configuration parameters. In our case, we want to disable the need for packages to compile with MPI support and reduce the number of versions of certain libraries, e.g. always compile libxml2 with python support. $SPACK_ROOT/etc/spack/modules.yaml Defines the organization and general settings for creating module files. For example, in our cause we have suffixes to differentiate versions that depend on Python 2.7 and 3.7 and only the lmod modules are enabled.","title":"Configuration"},{"location":"general/cvmfs/#adding-a-module","text":"Adding a new module is fairly straight forward. On the CVMFS origin host, log in as the connect user. Now start a CVMFS transaction: cvmfs_server transaction connect.opensciencegrid.org Please note that only a single transaction can be open at a time, so if you don't finish the transaction (for example building ROOT takes hours) no one else can add new modules while a transaction is active. Once the transaction has been started, go to the spack bin directory, $SPACK_ROOT/bin/ : cd /cvmfs/connect.opensciencegrid.org/modules/spack/bin If the desired piece of software and version is available in the (spack package list)[https://spack.readthedocs.io/en/latest/package_list.html], simply run spack install <package>@<version>%gcc@<gcc_version> To check what <gcc_version> s are available see $HOME/.spack/linux/compilers.yaml Adding a new version of a piece of software requires editing the respective package file using spack edit <package> Adding a new package is fairly straightforward as well. Simply run spack create <url_to_package_tarball> and edit the resulting file as needed, e.g. add dependencies, add configure/cmake options, etc. For examples check out various other packages in $SPACK_ROOT/var/spack/repos/builtin/packages/ .","title":"Adding a Module"},{"location":"general/cvmfs/#experiments","text":"","title":"Experiments"},{"location":"general/cvmfs/#spt","text":"See Midscale-Engagements","title":"SPT"},{"location":"general/cvmfs/#xenon","text":"See Midscale-Engagements","title":"XENON"},{"location":"general/cvmfs/#veritas","text":"See Midscale-Engagements","title":"VERITAS"},{"location":"general/cvmfs/#nexo","text":"The nEXO repository is handled by OSG personnel. The organization is the same as the SPT repos. The repo is very much in flux because of the development of the nEXO MonteCarlo software.","title":"nEXO"},{"location":"general/cvmfs/#dependency-list","text":"Shortened list Boost 1.67.0 cmake 3.11.1 geant4 10.04.p01 python 2.7.14 ROOT 6.12.06 with builtin_fftw3, using our gsl 1.16, minuit on, caster off, roofit on, rfio off, xrootd off, gfal and ruby disabled vgm 4.4 http://ivana.home.cern.ch","title":"Dependency List"},{"location":"midscale-engagements/spt/cvmfs/","text":"CVMFS \u00b6 The SPT repo is handled by the experiment. The point of contact is Nathan Whitehorn. The structure follows a fairly simple pattern: py2-v1/<os_architecture> , py3-v1/<os_architecture> , etc. The initial indicates the python version (py2 vs py3) and then the version of the other dependencies, where v1 is the minimal version required to run the SPT code and ever increasing versions are newer versions of the dependencies. At the moment, v4 is the bleeding edge`. For each combination of python and dependency set version there will be a version delineated by OS version and CPU architecture. Dependency List \u00b6 gcc binutils python python-setuptools python-pip boost hdf5 netcdf fftw gsl gnuplot pgplot tcl bzip zlib xz cmake flac freetype cfitsio openblas globus-toolkit numpy scipy ipython jupyter pyfits astropy numexpr Cython matplotlib Sphinx tables urwid pyFFTW healpy spectrum tornado SQLAlchemy PyYAML ephem idlsave ipdb jsonschema h5py pandas line_profiler memory_profiler simplejson joblib lmfit","title":"CVMFS"},{"location":"midscale-engagements/spt/cvmfs/#cvmfs","text":"The SPT repo is handled by the experiment. The point of contact is Nathan Whitehorn. The structure follows a fairly simple pattern: py2-v1/<os_architecture> , py3-v1/<os_architecture> , etc. The initial indicates the python version (py2 vs py3) and then the version of the other dependencies, where v1 is the minimal version required to run the SPT code and ever increasing versions are newer versions of the dependencies. At the moment, v4 is the bleeding edge`. For each combination of python and dependency set version there will be a version delineated by OS version and CPU architecture.","title":"CVMFS"},{"location":"midscale-engagements/spt/cvmfs/#dependency-list","text":"gcc binutils python python-setuptools python-pip boost hdf5 netcdf fftw gsl gnuplot pgplot tcl bzip zlib xz cmake flac freetype cfitsio openblas globus-toolkit numpy scipy ipython jupyter pyfits astropy numexpr Cython matplotlib Sphinx tables urwid pyFFTW healpy spectrum tornado SQLAlchemy PyYAML ephem idlsave ipdb jsonschema h5py pandas line_profiler memory_profiler simplejson joblib lmfit","title":"Dependency List"},{"location":"midscale-engagements/spt/general/","text":"South Pole Telescope \u00b6 SPT-3G, the third generation camera on the South Pole Telescope (SPT), was deployed in the 2016-2017 Austral summer season. The SPT is a 10-meter telescope located at the geographic South Pole and designed for observations in the millimeter-wave and submillimeter-wave regions of the electromagnetic spectrum. The SPT is primarily used to study the cosmic microwave background (CMB). Requirements \u00b6 The upgraded camera produces an order of magnitude more data than the previous generations of SPT cameras. The telescope is expected to collect a petabyte (PB) of data over course of five years, which is a significantly larger data volume than any other CMB telescope in operation. The increase in data rate required radical changes to the SPT computing model both at the South Pole and University of Chicago. This paper will describe the overall integration of distributed storage and compute resources into a common interface, deployment of on-site data reduction and storage infrastructure, and the usage of the Open Science Grid (OSG) by the SPT collaboration. Data requirements: ~ 150-200 TB of compressed raw data coming north every year in big boxes of hard drives ~30 TB/year of reduced-rate data arriving continuously by satellite. Computing Requirements: ~ 150 cores with 4 GB ~ 10M core hours Resources \u00b6 SPT has two dedicated login nodes. These are used for user analysis and job submission to OSG. To facilitate user analysis, there are Jupyterhub instances running on each of the login nodes. In addition to the login nodes, there are two dedicated production resources: spt-buffer and spt-mgmt . spt-buffer is dedicated virtual machine that is required to retrieve the data via satellite from pole. United States Antarctic Program (USAP) NERSC Backups \u00b6 There is automated","title":"General"},{"location":"midscale-engagements/spt/general/#south-pole-telescope","text":"SPT-3G, the third generation camera on the South Pole Telescope (SPT), was deployed in the 2016-2017 Austral summer season. The SPT is a 10-meter telescope located at the geographic South Pole and designed for observations in the millimeter-wave and submillimeter-wave regions of the electromagnetic spectrum. The SPT is primarily used to study the cosmic microwave background (CMB).","title":"South Pole Telescope"},{"location":"midscale-engagements/spt/general/#requirements","text":"The upgraded camera produces an order of magnitude more data than the previous generations of SPT cameras. The telescope is expected to collect a petabyte (PB) of data over course of five years, which is a significantly larger data volume than any other CMB telescope in operation. The increase in data rate required radical changes to the SPT computing model both at the South Pole and University of Chicago. This paper will describe the overall integration of distributed storage and compute resources into a common interface, deployment of on-site data reduction and storage infrastructure, and the usage of the Open Science Grid (OSG) by the SPT collaboration. Data requirements: ~ 150-200 TB of compressed raw data coming north every year in big boxes of hard drives ~30 TB/year of reduced-rate data arriving continuously by satellite. Computing Requirements: ~ 150 cores with 4 GB ~ 10M core hours","title":"Requirements"},{"location":"midscale-engagements/spt/general/#resources","text":"SPT has two dedicated login nodes. These are used for user analysis and job submission to OSG. To facilitate user analysis, there are Jupyterhub instances running on each of the login nodes. In addition to the login nodes, there are two dedicated production resources: spt-buffer and spt-mgmt . spt-buffer is dedicated virtual machine that is required to retrieve the data via satellite from pole. United States Antarctic Program (USAP)","title":"Resources"},{"location":"midscale-engagements/spt/general/#nersc-backups","text":"There is automated","title":"NERSC Backups"},{"location":"midscale-engagements/veritas/cvmfs/","text":"CVMFS \u00b6 The VERITAS repository is handled by OSG personnel. It is currently static. The organization is the same as the SPT repos. One thing to note is the need for GCC 4.9.x because of the version of ROOT required. This may change in the future. future. Dependency List \u00b6 Shortened list ROOT GEANT4 python CORSIKA","title":"CVMFS"},{"location":"midscale-engagements/veritas/cvmfs/#cvmfs","text":"The VERITAS repository is handled by OSG personnel. It is currently static. The organization is the same as the SPT repos. One thing to note is the need for GCC 4.9.x because of the version of ROOT required. This may change in the future. future.","title":"CVMFS"},{"location":"midscale-engagements/veritas/cvmfs/#dependency-list","text":"Shortened list ROOT GEANT4 python CORSIKA","title":"Dependency List"},{"location":"midscale-engagements/veritas/general/","text":"","title":"General"},{"location":"midscale-engagements/xenon/cvmfs/","text":"CVMFS \u00b6 The SPT repo is handled by the experiment. The repo is automatically updated whenever there is a an update to the XENON1T GitHub repository using DeployHQ. The software itself is being deployed through anaconda. Dependency List \u00b6 Shortened list ROOT GEANT4 python3","title":"CVMFS"},{"location":"midscale-engagements/xenon/cvmfs/#cvmfs","text":"The SPT repo is handled by the experiment. The repo is automatically updated whenever there is a an update to the XENON1T GitHub repository using DeployHQ. The software itself is being deployed through anaconda.","title":"CVMFS"},{"location":"midscale-engagements/xenon/cvmfs/#dependency-list","text":"Shortened list ROOT GEANT4 python3","title":"Dependency List"},{"location":"midscale-engagements/xenon/general/","text":"XENON \u00b6 Requirements \u00b6 Resources \u00b6 Rucio \u00b6","title":"General"},{"location":"midscale-engagements/xenon/general/#xenon","text":"","title":"XENON"},{"location":"midscale-engagements/xenon/general/#requirements","text":"","title":"Requirements"},{"location":"midscale-engagements/xenon/general/#resources","text":"","title":"Resources"},{"location":"midscale-engagements/xenon/general/#rucio","text":"","title":"Rucio"}]}